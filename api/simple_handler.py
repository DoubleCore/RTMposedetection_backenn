"""
ç®€åŒ–çš„æ–‡ä»¶å¤„ç†æ¥å£
ä¸“é—¨å¤„ç†RTMPoseæ£€æµ‹å’Œç»“æœè¾“å‡º
"""

import cv2
import numpy as np
import os
import json
import uuid
from datetime import datetime
from typing import Dict, Any, Tuple, List, Optional
import logging

from models.rtmpose.detector import get_rtmpose_detector
from utils.exceptions import ProcessingError
from utils.video_processor import get_frame_extractor

logger = logging.getLogger(__name__)

class SimpleFileHandler:
    """
    ç®€åŒ–çš„æ–‡ä»¶å¤„ç†å™¨
    """
    
    def __init__(self, output_dir: str = "output"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        self.json_dir = os.path.join(output_dir, "json")
        self.pose_dir = os.path.join(output_dir, "pose")  # é‡å‘½åï¼šimages -> pose
        self.sam_dir = os.path.join(output_dir, "sam")    # æ–°å¢ï¼šSAMåˆ†å‰²ç»“æœ
        self.origin_dir = os.path.join(output_dir, "origin")
        self.temp_dir = os.path.join(output_dir, "temp")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        for dir_path in [self.output_dir, self.json_dir, self.pose_dir, self.sam_dir, self.origin_dir, self.temp_dir]:
            os.makedirs(dir_path, exist_ok=True)
        
        # è·å–RTMPoseæ£€æµ‹å™¨å’Œè§†é¢‘å¸§æå–å™¨
        self.detector = get_rtmpose_detector()
        self.frame_extractor = get_frame_extractor(output_dir)
        
        logger.info(f"ç®€åŒ–æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºç›®å½•: {output_dir}")
    
    async def process_image_file(self, file_path: str, task_id: str, filename: str) -> Dict[str, Any]:
        """
        å¤„ç†å›¾ç‰‡æ–‡ä»¶
        
        Args:
            file_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            task_id: ä»»åŠ¡ID
            filename: åŸå§‹æ–‡ä»¶å
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            logger.info(f"ğŸ–¼ï¸ å¼€å§‹å¤„ç†å›¾ç‰‡: {filename}")
            
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(file_path)
            if image is None:
                raise ProcessingError("æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶")
            
            # RTMPoseå§¿æ€æ£€æµ‹
            keypoints, scores = self.detector.detect_pose_simple(image)
            num_persons = len(keypoints)
            
            logger.info(f"ğŸ‘¥ æ£€æµ‹åˆ° {num_persons} ä¸ªäºº")
            
            # åˆ›å»ºJSONç»“æœ
            json_result = {
                "task_id": task_id,
                "file_name": filename,
                "file_type": "image",
                "image_size": {
                    "width": int(image.shape[1]),
                    "height": int(image.shape[0])
                },
                "analysis_time": datetime.now().isoformat(),
                "num_persons": num_persons,
                "model_info": {
                    "model_name": self.detector.model_name,
                    "mode": self.detector.mode,
                    "confidence_threshold": self.detector.confidence_threshold
                },
                "persons": []
            }
            
            # æ·»åŠ æ¯ä¸ªäººçš„å…³é”®ç‚¹æ•°æ®
            for person_idx in range(num_persons):
                person_data = {
                    "person_id": person_idx,
                    "keypoints": keypoints[person_idx].tolist(),
                    "scores": scores[person_idx].tolist(),
                    "skeleton_format": "COCO17",
                    "keypoint_names": self.detector.keypoint_names,
                    "avg_confidence": float(np.mean(scores[person_idx]))
                }
                json_result["persons"].append(person_data)
            
            # ä¿å­˜JSONç»“æœ
            json_path = os.path.join(self.json_dir, f"{task_id}.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_result, f, indent=2, ensure_ascii=False)
            
            # ç»˜åˆ¶å¹¶ä¿å­˜æ ‡æ³¨å›¾ç‰‡
            annotated_image = self.detector.draw_pose_on_image(image, keypoints, scores)
            annotated_filename = f"{task_id}_frame1.jpg"
            annotated_path = os.path.join(self.pose_dir, annotated_filename)
            cv2.imwrite(annotated_path, annotated_image)
            
            logger.info(f"âœ… å›¾ç‰‡å¤„ç†å®Œæˆ: JSON={json_path}, å›¾ç‰‡={annotated_path}")
            
            return {
                "type": "image",
                "num_persons": num_persons,
                "json_file": f"{task_id}.json",
                "annotated_image": annotated_filename,
                "processing_time": "immediate",
                "results": json_result
            }
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
            raise ProcessingError(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
    
    async def process_video_file(self, file_path: str, task_id: str, filename: str) -> Dict[str, Any]:
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶ï¼ˆæ–°æµç¨‹ï¼šå…ˆæå–å¸§â†’å†è¿›è¡Œå§¿æ€æ£€æµ‹ï¼‰
        
        Args:
            file_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            task_id: ä»»åŠ¡ID
            filename: åŸå§‹æ–‡ä»¶å
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            logger.info(f"ğŸ¥ å¼€å§‹å¤„ç†è§†é¢‘: {filename}")
            
            # ç¬¬ä¸€æ­¥ï¼šæå–è§†é¢‘å¸§åˆ° origin ç›®å½•
            logger.info("ğŸ“¸ ç¬¬ä¸€æ­¥ï¼šæå–è§†é¢‘å¸§åˆ°åŸå§‹ç›®å½•...")
            extraction_result = self.frame_extractor.extract_frames(
                video_path=file_path,
                task_id=task_id,
                max_frames=None,  # æå–æ‰€æœ‰å¸§
                sample_method="all"  # ä¿®æ”¹ä¸ºæå–æ‰€æœ‰å¸§
            )
            
            extracted_frames = extraction_result["extracted_frames"]
            video_info = extraction_result["video_info"]
            
            logger.info(f"âœ… å¸§æå–å®Œæˆ: æå–äº† {len(extracted_frames)} å¸§åˆ° origin ç›®å½•")
            
            # ç¬¬äºŒæ­¥ï¼šå¯¹æå–çš„å¸§è¿›è¡Œå§¿æ€æ£€æµ‹
            logger.info("ğŸ¤– ç¬¬äºŒæ­¥ï¼šå¯¹åŸå§‹å¸§è¿›è¡Œå§¿æ€æ£€æµ‹...")
            
            processed_frames = []
            annotated_images = []
            total_persons = 0
            
            for frame_info in extracted_frames:
                frame_path = frame_info["file_path"]
                frame_number = frame_info["frame_number"]
                original_frame_index = frame_info["original_frame_index"]
                timestamp = frame_info["timestamp"]
                
                try:
                    # è¯»å–åŸå§‹å¸§å›¾åƒ
                    image = cv2.imread(frame_path)
                    if image is None:
                        logger.warning(f"âš ï¸ æ— æ³•è¯»å–å¸§å›¾åƒ: {frame_path}")
                        continue
                    
                    # RTMPoseå§¿æ€æ£€æµ‹
                    keypoints, scores = self.detector.detect_pose_simple(image)
                    num_persons = len(keypoints)
                    total_persons += num_persons
                    
                    # è®°å½•å¸§æ•°æ®
                    frame_data = {
                        "frame_number": frame_number,
                        "original_frame_index": original_frame_index,
                        "timestamp": timestamp,
                        "num_persons": num_persons,
                        "origin_image": frame_info["filename"],
                        "persons": []
                    }
                    
                    # æ·»åŠ äººå‘˜æ•°æ®
                    for person_idx in range(num_persons):
                        person_data = {
                            "person_id": person_idx,
                            "keypoints": keypoints[person_idx].tolist(),
                            "scores": scores[person_idx].tolist(),
                            "skeleton_format": "COCO17",
                            "keypoint_names": self.detector.keypoint_names,
                            "avg_confidence": float(np.mean(scores[person_idx]))
                        }
                        frame_data["persons"].append(person_data)
                    
                    processed_frames.append(frame_data)
                    
                    # ä¸ºæ¯ä¸ªå¸§ä¿å­˜ç‹¬ç«‹çš„JSONæ–‡ä»¶
                    frame_json_result = {
                        "task_id": task_id,
                        "file_name": filename,
                        "file_type": "video_frame",
                        "frame_number": frame_number,
                        "original_frame_index": original_frame_index,
                        "timestamp": timestamp,
                        "image_size": {
                            "width": int(image.shape[1]),
                            "height": int(image.shape[0])
                        },
                        "analysis_time": datetime.now().isoformat(),
                        "num_persons": num_persons,
                        "model_info": {
                            "model_name": self.detector.model_name,
                            "mode": self.detector.mode,
                            "confidence_threshold": self.detector.confidence_threshold
                        },
                        "origin_image": frame_info["filename"],
                        "persons": frame_data["persons"]
                    }
                    
                    # ä¿å­˜å•å¸§JSONæ–‡ä»¶ - ä½¿ç”¨ä¸å›¾ç‰‡ç›¸åŒçš„å‘½åï¼šframe_n.json
                    frame_json_filename = f"frame_{frame_number}.json"
                    frame_json_path = os.path.join(self.json_dir, frame_json_filename)
                    with open(frame_json_path, 'w', encoding='utf-8') as f:
                        json.dump(frame_json_result, f, indent=2, ensure_ascii=False)
                    
                    # ä¿å­˜æ ‡æ³¨å›¾ç‰‡ - ç®€åŒ–å‘½åï¼šframe_n.jpg
                    annotated_frame = self.detector.draw_pose_on_image(image, keypoints, scores)
                    annotated_filename = f"frame_{frame_number}.jpg"
                    annotated_path = os.path.join(self.pose_dir, annotated_filename)
                    cv2.imwrite(annotated_path, annotated_frame)
                    annotated_images.append(annotated_filename)
                    
                    # è¿›åº¦æ—¥å¿—ä¼˜åŒ–
                    if frame_number % 100 == 0:  # æ¯100å¸§æ‰“å°ä¸€æ¬¡
                        logger.info(f"âœ… å·²å¤„ç† {frame_number} å¸§...")
                    elif frame_number <= 10:  # å‰10å¸§æ¯å¸§éƒ½æ‰“å°
                        logger.info(f"âœ… å¤„ç†å¸§ {frame_number}: æ£€æµ‹åˆ° {num_persons} ä¸ªäºº (åŸå§‹å¸§å·: {original_frame_index})")
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å¸§ {frame_number} å¤±è´¥: {str(e)}")
                    continue
            
            # åˆ›å»ºJSONç»“æœ
            json_result = {
                "task_id": task_id,
                "file_name": filename,
                "file_type": "video",
                "video_info": video_info,
                "extraction_info": extraction_result["extraction_info"],
                "analysis_time": datetime.now().isoformat(),
                "processed_frames": len(processed_frames),
                "total_persons_detected": total_persons,
                "model_info": {
                    "model_name": self.detector.model_name,
                    "mode": self.detector.mode,
                    "confidence_threshold": self.detector.confidence_threshold
                },
                "frames": processed_frames,
                "file_structure": {
                    "origin_frames": [f["filename"] for f in extracted_frames],
                    "annotated_frames": annotated_images
                }
            }
            
            # ä¿å­˜JSONç»“æœ
            json_path = os.path.join(self.json_dir, f"{task_id}.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_result, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ: JSON={json_path}")
            logger.info(f"ğŸ“ åŸå§‹å¸§æ•°: {len(extracted_frames)}, æ ‡æ³¨å¸§æ•°: {len(annotated_images)}")
            
            return {
                "type": "video",
                "video_info": video_info,
                "extraction_info": extraction_result["extraction_info"],
                "processed_frames": len(processed_frames),
                "total_persons_detected": total_persons,
                "json_file": f"{task_id}.json",
                "annotated_images": annotated_images,
                "origin_images": [f["filename"] for f in extracted_frames],
                "processing_time": f"{len(processed_frames)} frames processed",
                "results": json_result
            }
            
        except Exception as e:
            logger.error(f"è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            raise ProcessingError(f"è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}")
    
    def get_result_files(self, task_id: str) -> Dict[str, Any]:
        """
        è·å–ä»»åŠ¡çš„ç»“æœæ–‡ä»¶è·¯å¾„
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        json_path = os.path.join(self.json_dir, f"{task_id}.json")
        
        # æŸ¥æ‰¾æ ‡æ³¨å›¾ç‰‡æ–‡ä»¶ (frame_n.jpgæ ¼å¼)
        annotated_files = []
        for filename in os.listdir(self.pose_dir):
            if filename.startswith("frame_") and filename.endswith(".jpg"):
                annotated_files.append(filename)
        
        # æŸ¥æ‰¾åŸå§‹å¸§æ–‡ä»¶ (frame_n.jpgæ ¼å¼)
        origin_files = []
        for filename in os.listdir(self.origin_dir):
            if filename.startswith("frame_") and filename.endswith(".jpg"):
                origin_files.append(filename)
        
        # æŒ‰å¸§å·æ’åº
        def extract_frame_number(filename):
            try:
                return int(filename.split('_')[1].split('.')[0])
            except:
                return 0
        
        annotated_files.sort(key=extract_frame_number)
        origin_files.sort(key=extract_frame_number)
        
        return {
            "json_file": json_path if os.path.exists(json_path) else None,
            "annotated_images": annotated_files,
            "origin_images": origin_files,
            "total_files": len(annotated_files) + len(origin_files) + (1 if os.path.exists(json_path) else 0)
        }
    
    def cleanup_temp_files(self, max_age_hours: int = 24):
        """
        æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        
        Args:
            max_age_hours: æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        """
        import time
        
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        
        for filename in os.listdir(self.temp_dir):
            file_path = os.path.join(self.temp_dir, filename)
            if os.path.isfile(file_path):
                file_age = current_time - os.path.getmtime(file_path)
                if file_age > max_age_seconds:
                    try:
                        os.remove(file_path)
                        logger.info(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {filename}")
                    except Exception as e:
                        logger.error(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {filename}, {str(e)}")

# å…¨å±€å¤„ç†å™¨å®ä¾‹
_handler_instance = None

def get_file_handler(output_dir: str = "output") -> SimpleFileHandler:
    """
    è·å–æ–‡ä»¶å¤„ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        æ–‡ä»¶å¤„ç†å™¨å®ä¾‹
    """
    global _handler_instance
    
    if _handler_instance is None:
        _handler_instance = SimpleFileHandler(output_dir)
    
    return _handler_instance 